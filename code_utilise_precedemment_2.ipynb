{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trouver_difference(str1, str2):\n",
    "    # Trouver les mots dans chaque chaîne\n",
    "    mots_str1 = set(str1.split())\n",
    "    mots_str2 = set(str2.split())\n",
    "    \n",
    "    # Trouver les mots qui sont dans une chaîne mais pas dans l'autre\n",
    "    diff = mots_str1.symmetric_difference(mots_str2)\n",
    "    \n",
    "    # Retourner la différence sous forme de chaîne\n",
    "    return ' '.join(diff)\n",
    "\n",
    "# Exemples d'utilisation\n",
    "diff1 = trouver_difference(\"RTE DE BAPAUME\", \"ROUTE DE BAPAUME\")\n",
    "diff2 = trouver_difference(\"RUE DS TRIBUNAUX\", \"RUE DES TRIBUNAUX\")\n",
    "diff3 = trouver_difference(\"RUE FERDINAND DECARPENTRY\", \"RUE DECARPENTRY\")\n",
    "\n",
    "print(diff1)  # Output: OU\n",
    "print(diff2)  # Output: E\n",
    "print(diff3)  # Output: FERDINAND\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import randint\n",
    "from difflib import SequenceMatcher\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"df_avec_dist_lev_prop\"\n",
    "df = pd.read_csv(PATH,encoding=\"UTF8\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"CEHDF_BAN_GEOCODAGE.csv\"\n",
    "df_b = pd.read_csv(PATH,encoding=\"UTF8\")\n",
    "df_b.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions \n",
    "def lev(s, t):\n",
    "    m = len(s)\n",
    "    n = len(t)\n",
    "    d = [[0] * (n + 1) for i in range(m + 1)]  \n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        d[i][0] = i\n",
    "\n",
    "    for j in range(1, n + 1):\n",
    "        d[0][j] = j\n",
    "    \n",
    "    for j in range(1, n + 1):\n",
    "        for i in range(1, m + 1):\n",
    "            if s[i - 1] == t[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            d[i][j] = min(d[i - 1][j] + 1,      # deletion\n",
    "                          d[i][j - 1] + 1,      # insertion\n",
    "                          d[i - 1][j - 1] + cost) # substitution   \n",
    "\n",
    "    return d[m][n]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate the \n",
    "# Jaro Similarity of two strings \n",
    "def jaro_distance(s1, s2) :\n",
    "\n",
    "\t# If the strings are equal \n",
    "\tif (s1 == s2) :\n",
    "\t\treturn 1.0; \n",
    "\n",
    "\t# Length of two strings \n",
    "\tlen1 = len(s1);\n",
    "\tlen2 = len(s2); \n",
    "\n",
    "\tif (len1 == 0 or len2 == 0) :\n",
    "\t\treturn 0.0; \n",
    "\n",
    "\t# Maximum distance upto which matching \n",
    "\t# is allowed \n",
    "\tmax_dist = (max(len(s1), len(s2)) // 2 ) - 1; \n",
    "\n",
    "\t# Count of matches \n",
    "\tmatch = 0; \n",
    "\n",
    "\t# Hash for matches \n",
    "\thash_s1 = [0] * len(s1) ;\n",
    "\thash_s2 = [0] * len(s2) ; \n",
    "\n",
    "\t# Traverse through the first string \n",
    "\tfor i in range(len1) : \n",
    "\n",
    "\t\t# Check if there is any matches \n",
    "\t\tfor j in range( max(0, i - max_dist), \n",
    "\t\t\t\t\tmin(len2, i + max_dist + 1)) : \n",
    "\t\t\t\n",
    "\t\t\t# If there is a match \n",
    "\t\t\tif (s1[i] == s2[j] and hash_s2[j] == 0) : \n",
    "\t\t\t\thash_s1[i] = 1; \n",
    "\t\t\t\thash_s2[j] = 1; \n",
    "\t\t\t\tmatch += 1; \n",
    "\t\t\t\tbreak; \n",
    "\t\t\n",
    "\t# If there is no match \n",
    "\tif (match == 0) :\n",
    "\t\treturn 0.0; \n",
    "\n",
    "\t# Number of transpositions \n",
    "\tt = 0; \n",
    "\n",
    "\tpoint = 0; \n",
    "\n",
    "\t# Count number of occurrences \n",
    "\t# where two characters match but \n",
    "\t# there is a third matched character \n",
    "\t# in between the indices \n",
    "\tfor i in range(len1) : \n",
    "\t\tif (hash_s1[i]) :\n",
    "\n",
    "\t\t\t# Find the next matched character \n",
    "\t\t\t# in second string \n",
    "\t\t\twhile (hash_s2[point] == 0) :\n",
    "\t\t\t\tpoint += 1; \n",
    "\n",
    "\t\t\tif (s1[i] != s2[point]) :\n",
    "\t\t\t\tpoint += 1;\n",
    "\t\t\t\tt += 1;\n",
    "\t\t\telse :\n",
    "\t\t\t\tpoint += 1;\n",
    "\t\t\t\t\n",
    "\t\tt /= 2; \n",
    "\n",
    "\t# Return the Jaro Similarity \n",
    "\treturn ((match / len1 + match / len2 +\n",
    "\t\t\t(match - t) / match ) / 3.0); \n",
    "\n",
    "# Jaro Winkler Similarity \n",
    "def jaro_Winkler(s1, s2) : \n",
    "\n",
    "\tjaro_dist = jaro_distance(s1, s2); \n",
    "\n",
    "\t# If the jaro Similarity is above a threshold \n",
    "\tif (jaro_dist > 0.7) :\n",
    "\n",
    "\t\t# Find the length of common prefix \n",
    "\t\tprefix = 0; \n",
    "\n",
    "\t\tfor i in range(min(len(s1), len(s2))) :\n",
    "\t\t\n",
    "\t\t\t# If the characters match \n",
    "\t\t\tif (s1[i] == s2[i]) :\n",
    "\t\t\t\tprefix += 1; \n",
    "\n",
    "\t\t\t# Else break \n",
    "\t\t\telse :\n",
    "\t\t\t\tbreak; \n",
    "\n",
    "\t\t# Maximum of 4 characters are allowed in prefix \n",
    "\t\tprefix = min(4, prefix); \n",
    "\n",
    "\t\t# Calculate jaro winkler Similarity \n",
    "\t\tjaro_dist += 0.1 * prefix * (1 - jaro_dist); \n",
    "\n",
    "\treturn jaro_dist; \n",
    "\n",
    "# Driver code \n",
    "if __name__ == \"__main__\" : \n",
    "\n",
    "\ts1 = \"TRATE\"; s2 = \"TRACE\"; \n",
    "\n",
    "\t# Print Jaro-Winkler Similarity of two strings \n",
    "\tprint(\"Jaro-Winkler Similarity =\", jaro_Winkler(s1, s2)) ; \n",
    "\n",
    "def lcs_dist(a,b):\n",
    "    s = SequenceMatcher(a=a, b=b)\n",
    "    return list(s.find_longest_match(0, len(a), 0, len(b)))[2]\n",
    "\n",
    "def process_df(df, df_b, filter_conditions, score_func, proposition_col):\n",
    "    i = 0\n",
    "    for _, row in df.iterrows():\n",
    "        df_b_filtered = df_b[filter_conditions(df_b, row)]\n",
    "        if not df_b_filtered.empty:\n",
    "            scores = df_b_filtered['rue'].apply(lambda x: score_func(str(x), str(row['rue'])))\n",
    "            max_score_index = scores.idxmin() if score_func == lev else scores.idxmax()\n",
    "            proposition_max_score = df_b_filtered.loc[max_score_index].copy()\n",
    "            df.at[_, proposition_col] = proposition_max_score['rue']\n",
    "            \n",
    "        else:  \n",
    "            df.at[_, proposition_col] = \"rien\"\n",
    "            \n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processed {i} rows\")\n",
    "    return df\n",
    "\n",
    "filter_conditions = lambda df_b, row: (\n",
    "    (df_b['numero'] == row['numero']) &\n",
    "    (df_b['rep'] == row['rep']) &\n",
    "    (df_b['commune'] == row['commune'])\n",
    ")\n",
    "\n",
    "filter_conditions_com = lambda df_b, row: (\n",
    "    (df_b['commune'] == row['commune'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.fillna('1', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_BAN = df_b[['commune','rue','libelle_commune']].groupby(['commune','rue','libelle_commune']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_compute = df[['commune','rue_x','libelle_commune']].groupby(['commune','rue_x','libelle_commune']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_BAN.loc[dataframe_BAN['commune'] == 80650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_to_compute.merge(dataframe_BAN, on=['commune','libelle_commune'] , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from textdistance import levenshtein\n",
    "#test['levenshtein_communes'] = test.apply(lambda x: levenshtein.distance(x['rue_x'], x['rue_y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna('rien', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "Levenshtein.distance(\"lewenstein\", \"levenshtein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = test.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lev_distance_communes'] = test.apply(lambda row: Levenshtein.distance(row['rue_x'], row['rue']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import randint\n",
    "from difflib import SequenceMatcher\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs_dist(a,b):\n",
    "    s = SequenceMatcher(a=a, b=b)\n",
    "    return list(s.find_longest_match(0, len(a), 0, len(b)))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lcs_commune'] = test.apply(lambda row: lcs_dist(row['rue_x'], row['rue']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2 = test.groupby(['rue_x', 'commune','libelle_commune'])['lcs_commune'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultat_lcs = test.loc[idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultat_lcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Supposons que votre DataFrame s'appelle df\n",
    "# et qu'il a les colonnes 'numero', 'rep', 'rue_x', 'rue_y', et 'dist_lev'\n",
    "\n",
    "# Grouper par 'rue_x' et 'commune', puis trouver l'index de la valeur minimale de 'dist_lev'\n",
    "idx = test.groupby(['rue_x', 'commune','libelle_commune'])['lev_distance_communes'].idxmin()\n",
    "\n",
    "# Utiliser l'index pour obtenir les lignes correspondantes du DataFrame\n",
    "df_resultat = test.loc[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultat_lcs['rue_init'] = df_resultat_lcs['rue_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultat_lcs['rue_lcs_com'] = df_resultat_lcs['rue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultat_lcs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultat_lcs = df_resultat_lcs[['commune',  'libelle_commune','lcs_commune', 'rue_init', 'rue_lcs_com']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultat['rue_init'] = df_resultat['rue_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_resultat.merge(df_resultat_lcs, on= ['commune','libelle_commune','rue_init'] , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['rue_lev_com'] = test['rue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['commune', 'libelle_commune', 'lev_distance_communes',\n",
    "       'lcs_commune_x', 'rue_init', 'lcs_commune_y', 'rue_lcs_com',\n",
    "       'rue_lev_com']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rue_init'] = df['rue_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['commune', 'libelle_commune', 'numero', 'rep',\n",
    "       'rue_y', 'lev_distance', 'lev_distance', 'lcs', 'lcs_ratio1',\n",
    "       'lcs_ratio2', 'jaro-winkler', 'score_min', 'rue_init']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = df.merge(test, on= ['commune','libelle_commune','rue_init'] , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union.to_csv(\"DF_FINAL.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
