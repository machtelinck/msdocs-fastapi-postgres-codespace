{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ce code ne marchera pas en l'etat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "import pandas as pd\n",
    "import random\n",
    "from random import randint\n",
    "from difflib import SequenceMatcher\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonctions \n",
    "def lev(s, t):\n",
    "    m = len(s)\n",
    "    n = len(t)\n",
    "    d = [[0] * (n + 1) for i in range(m + 1)]  \n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        d[i][0] = i\n",
    "\n",
    "    for j in range(1, n + 1):\n",
    "        d[0][j] = j\n",
    "    \n",
    "    for j in range(1, n + 1):\n",
    "        for i in range(1, m + 1):\n",
    "            if s[i - 1] == t[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            d[i][j] = min(d[i - 1][j] + 1,      # deletion\n",
    "                          d[i][j - 1] + 1,      # insertion\n",
    "                          d[i - 1][j - 1] + cost) # substitution   \n",
    "\n",
    "    return d[m][n]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate the \n",
    "# Jaro Similarity of two strings \n",
    "def jaro_distance(s1, s2) :\n",
    "\n",
    "\t# If the strings are equal \n",
    "\tif (s1 == s2) :\n",
    "\t\treturn 1.0; \n",
    "\n",
    "\t# Length of two strings \n",
    "\tlen1 = len(s1);\n",
    "\tlen2 = len(s2); \n",
    "\n",
    "\tif (len1 == 0 or len2 == 0) :\n",
    "\t\treturn 0.0; \n",
    "\n",
    "\t# Maximum distance upto which matching \n",
    "\t# is allowed \n",
    "\tmax_dist = (max(len(s1), len(s2)) // 2 ) - 1; \n",
    "\n",
    "\t# Count of matches \n",
    "\tmatch = 0; \n",
    "\n",
    "\t# Hash for matches \n",
    "\thash_s1 = [0] * len(s1) ;\n",
    "\thash_s2 = [0] * len(s2) ; \n",
    "\n",
    "\t# Traverse through the first string \n",
    "\tfor i in range(len1) : \n",
    "\n",
    "\t\t# Check if there is any matches \n",
    "\t\tfor j in range( max(0, i - max_dist), \n",
    "\t\t\t\t\tmin(len2, i + max_dist + 1)) : \n",
    "\t\t\t\n",
    "\t\t\t# If there is a match \n",
    "\t\t\tif (s1[i] == s2[j] and hash_s2[j] == 0) : \n",
    "\t\t\t\thash_s1[i] = 1; \n",
    "\t\t\t\thash_s2[j] = 1; \n",
    "\t\t\t\tmatch += 1; \n",
    "\t\t\t\tbreak; \n",
    "\t\t\n",
    "\t# If there is no match \n",
    "\tif (match == 0) :\n",
    "\t\treturn 0.0; \n",
    "\n",
    "\t# Number of transpositions \n",
    "\tt = 0; \n",
    "\n",
    "\tpoint = 0; \n",
    "\n",
    "\t# Count number of occurrences \n",
    "\t# where two characters match but \n",
    "\t# there is a third matched character \n",
    "\t# in between the indices \n",
    "\tfor i in range(len1) : \n",
    "\t\tif (hash_s1[i]) :\n",
    "\n",
    "\t\t\t# Find the next matched character \n",
    "\t\t\t# in second string \n",
    "\t\t\twhile (hash_s2[point] == 0) :\n",
    "\t\t\t\tpoint += 1; \n",
    "\n",
    "\t\t\tif (s1[i] != s2[point]) :\n",
    "\t\t\t\tpoint += 1;\n",
    "\t\t\t\tt += 1;\n",
    "\t\t\telse :\n",
    "\t\t\t\tpoint += 1;\n",
    "\t\t\t\t\n",
    "\t\tt /= 2; \n",
    "\n",
    "\t# Return the Jaro Similarity \n",
    "\treturn ((match / len1 + match / len2 +\n",
    "\t\t\t(match - t) / match ) / 3.0); \n",
    "\n",
    "# Jaro Winkler Similarity \n",
    "def jaro_Winkler(s1, s2) : \n",
    "\n",
    "\tjaro_dist = jaro_distance(s1, s2); \n",
    "\n",
    "\t# If the jaro Similarity is above a threshold \n",
    "\tif (jaro_dist > 0.7) :\n",
    "\n",
    "\t\t# Find the length of common prefix \n",
    "\t\tprefix = 0; \n",
    "\n",
    "\t\tfor i in range(min(len(s1), len(s2))) :\n",
    "\t\t\n",
    "\t\t\t# If the characters match \n",
    "\t\t\tif (s1[i] == s2[i]) :\n",
    "\t\t\t\tprefix += 1; \n",
    "\n",
    "\t\t\t# Else break \n",
    "\t\t\telse :\n",
    "\t\t\t\tbreak; \n",
    "\n",
    "\t\t# Maximum of 4 characters are allowed in prefix \n",
    "\t\tprefix = min(4, prefix); \n",
    "\n",
    "\t\t# Calculate jaro winkler Similarity \n",
    "\t\tjaro_dist += 0.1 * prefix * (1 - jaro_dist); \n",
    "\n",
    "\treturn jaro_dist; \n",
    "\n",
    "# Driver code \n",
    "if __name__ == \"__main__\" : \n",
    "\n",
    "\ts1 = \"TRATE\"; s2 = \"TRACE\"; \n",
    "\n",
    "\t# Print Jaro-Winkler Similarity of two strings \n",
    "\tprint(\"Jaro-Winkler Similarity =\", jaro_Winkler(s1, s2)) ; \n",
    "\n",
    "def lcs_dist(a,b):\n",
    "    s = SequenceMatcher(a=a, b=b)\n",
    "    return list(s.find_longest_match(0, len(a), 0, len(b)))[2]\n",
    "\n",
    "def process_df(df, df_b, filter_conditions, score_func, proposition_col):\n",
    "    i = 0\n",
    "    for _, row in df.iterrows():\n",
    "        df_b_filtered = df_b[filter_conditions(df_b, row)]\n",
    "        if not df_b_filtered.empty:\n",
    "            scores = df_b_filtered['rue'].apply(lambda x: score_func(str(x), str(row['rue'])))\n",
    "            max_score_index = scores.idxmin() if score_func == lev else scores.idxmax()\n",
    "            proposition_max_score = df_b_filtered.loc[max_score_index].copy()\n",
    "            df.at[_, proposition_col] = proposition_max_score['rue']\n",
    "            \n",
    "        else:  \n",
    "            df.at[_, proposition_col] = \"rien\"\n",
    "            \n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processed {i} rows\")\n",
    "    return df\n",
    "\n",
    "filter_conditions = lambda df_b, row: (\n",
    "    (df_b['numero'] == row['numero']) &\n",
    "    (df_b['rep'] == row['rep']) &\n",
    "    (df_b['commune'] == row['commune'])&\n",
    "    (df_b['libelle_commune'] == row['libelle_commune'])\n",
    "    \n",
    ")\n",
    "\n",
    "filter_conditions_com = lambda df_b, row: (\n",
    "    (df_b['commune'] == row['commune'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df alleger \n",
    "PATH = \"CEHDF_CLI_GEOCODAGE.csv\"\n",
    "df = pd.read_csv(PATH,encoding=\"UTF8\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"libelle_commune\"] = df[\"LIBELLE_COMMUNE_BAN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna('1', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.fillna('1', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b[\"numero\"] = df_b['numero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df_optimized(df, df_b, filter_conditions, score_func, proposition_col):\n",
    "    i = 0\n",
    "    a = 0\n",
    "\n",
    "    # Assurez-vous que les DataFrames ont des index réinitialisés\n",
    "    df = df.reset_index(drop=True)\n",
    "    df_b = df_b.reset_index(drop=True)\n",
    "\n",
    "    # Appliquez la fonction filter_conditions à chaque ligne de df\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        # Utilisez row directement pour obtenir des valeurs scalaires\n",
    "        df_b_filtered = df_b[filter_conditions(df_b, row)]\n",
    "        if not df_b_filtered.empty:\n",
    "            # Appliquez la fonction score_func à chaque 'rue' dans df_b_filtered\n",
    "            scores = df_b_filtered['rue'].apply(lambda x: score_func(str(x), str(row['rue'])))\n",
    "            max_score_index = scores.idxmin() if score_func == lev else scores.idxmax()\n",
    "            proposition_max_score = df_b_filtered.loc[max_score_index].copy()\n",
    "            df.at[index, proposition_col] = proposition_max_score['rue']\n",
    "        else:\n",
    "            df.at[index, proposition_col] = \"rien\"\n",
    "        i += 1\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i} rows\")\n",
    "        a = row['numero']\n",
    "        b = row['rep']\n",
    "        c = row['commune']\n",
    "        d = row['libelle_commune']\n",
    "\n",
    "    return df\n",
    "\n",
    "# Définissez la fonction filter_conditions pour utiliser row directement\n",
    "filter_conditions = lambda df_b, row: (\n",
    "    (df_b['rep'] == row['rep']) &\n",
    "    (df_b['commune'] == row['commune'])&\n",
    "    (df_b['libelle_commune'] == row['libelle_commune'])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "Levenshtein.distance(\"lewenstein\", \"levenshtein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['rep',\"commune\",\"libelle_commune\",\"numero\"], inplace=True,\n",
    "               ascending = [True, True, True , True])\n",
    "print(\"Get the DataFrame after sorting:\\n\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps= ['rep', 'rue', 'commune', 'libelle_commune', 'numero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[keeps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b = df_b[keeps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_BAN = df_b[['commune','rue','libelle_commune','numero','rep']].groupby(['commune','rue','libelle_commune','numero','rep']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_compute = df[['commune','rue','libelle_commune','numero','rep']].groupby(['commune','rue','libelle_commune','numero','rep']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_to_compute.merge(dataframe_BAN, on= ['commune','rep','libelle_commune','numero'] , how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['rue_y'].isnull().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_compute.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_BAN.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz.distance import Levenshtein\n",
    "Levenshtein.distance(\"lewenstein\", \"levenshtein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna('rien', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = test[test[\"rue_y\"]!= \"rien\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lev_distance'] = test.apply(lambda row: Levenshtein.distance(row['rue_x'], row['rue_y']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = test.groupby(['rue_x', 'commune','rep','libelle_commune','numero'])['lev_distance'].idxmin()\n",
    "\n",
    "# Utiliser l'index pour obtenir les lignes correspondantes du DataFrame\n",
    "df_resultat = test.loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for _, row in df_resultat.iterrows():\n",
    "    a = row['rue_x']\n",
    "    b= row['rue_y']\n",
    "    s = SequenceMatcher(a=a, b=b)\n",
    "\n",
    "\n",
    "           \n",
    "    df_resultat.at[_, 'lcs'] = list(s.find_longest_match(0, len(a), 0, len(b)))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_resultat.iterrows():\n",
    "\n",
    "  \n",
    "     # Faire la proposition avec le score le plus élevé\n",
    "    if not row[\"lcs\"]==0:\n",
    "\n",
    "            # Ajouter la proposition à la colonne 'proposition' dans df\n",
    "        df_resultat.at[_, 'lcs_ratio1'] = row[\"lcs\"]/len(row[\"rue_x\"])\n",
    "\n",
    "\n",
    "    else:  \n",
    "        df_resultat.at[_, 'lcs_ratio1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_resultat.iterrows():\n",
    "\n",
    "  \n",
    "     # Faire la proposition avec le score le plus élevé\n",
    "    if not row[\"lcs\"]==0:\n",
    "\n",
    "            # Ajouter la proposition à la colonne 'proposition' dans df\n",
    "        df_resultat.at[_, 'lcs_ratio2'] = row[\"lcs\"]/len(row[\"rue_y\"])\n",
    "\n",
    "\n",
    "    else:  \n",
    "        df_resultat.at[_, 'lcs_ratio2'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for _, row in df_resultat.iterrows():\n",
    "\n",
    "     # Faire la proposition avec le score le plus élevé\n",
    "    if not row[\"lcs\"]==0:\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "            # Ajouter la proposition à la colonne 'proposition' dans df\n",
    "        df_resultat.at[_, 'jaro-winkler'] = jaro_Winkler(row[\"rue_x\"],row[\"rue_y\"])\n",
    "\n",
    "            # Ajouter le score correspondant à la colonne 'score_max' dans df\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "    else:  \n",
    "        df_resultat.at[_, 'jaro-winkler'] = 0\n",
    "\n",
    "            # Ajouter le score correspondant à la colonne 'score_max' dans df\n",
    "        df_resultat.at[_, 'score_min'] = 10000\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"sample_rajout.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"RESULTAT_SAMPLE2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dff3.to_csv(\"RESULTAT_SAMPLE_JAROWINKLER.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultat.to_csv(\"df_avec_dist_lev_prop\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
