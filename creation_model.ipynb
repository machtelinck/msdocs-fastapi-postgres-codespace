{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/19 13:20:51 INFO mlflow.tracking.fluent: Experiment with name 'ML_FLOW_SETUP' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.95      0.93       365\n",
      "         1.0       0.85      0.78      0.81       135\n",
      "\n",
      "    accuracy                           0.90       500\n",
      "   macro avg       0.88      0.86      0.87       500\n",
      "weighted avg       0.90      0.90      0.90       500\n",
      "\n",
      "[[346  19]\n",
      " [ 30 105]]\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import textdistance\n",
    "\n",
    "# Configuration initiale de MLflow (facultatif)\n",
    "import mlflow\n",
    "experiment_name = \"ML_FLOW_SETUP\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Configurer MLflow pour utiliser un dossier local pour le stockage\n",
    "mlflow.set_tracking_uri(\"/workspace/ml_runs\")\n",
    "\n",
    "# Assurez-vous de créer le dossier s'il n'existe pas déjà\n",
    "\n",
    "\n",
    "\n",
    "# Lecture des données\n",
    "df = pd.read_excel(\"/workspace/DONNEE_LABEL_FAUX_REGROUPER.xlsx\")\n",
    "df2 = pd.read_excel(\"/workspace/DONNEE_LABEL_VRAI.xlsx\")\n",
    "# Votre prétraitement des données reste inchangé...\n",
    "i = 4000\n",
    "df = df.head(i)\n",
    "# i est la ou je me suis arreté\n",
    "# Renommer les colonnes par leur position\n",
    "df = df.rename(columns={df.columns[0]: 'rue_init', df.columns[1]: 'PROP_LEV',df.columns[2]: 'LABEL'})\n",
    "df = df.replace(np.nan, 0)\n",
    "df['TYPE_VOIE'] =  df['rue_init'].str.split(' ').str[0]\n",
    "df = df.replace(np.nan, 1)\n",
    "\n",
    "df2 = df2.replace(np.nan, 1)\n",
    "j = 1000\n",
    "# i est la ou je me suis arreté\n",
    "df2 = df2.head(j)\n",
    "df2 = df2.rename(columns={df2.columns[0]: 'rue_init', df2.columns[1]: 'PROP_LEV',df2.columns[2]: 'LABEL'})\n",
    "\n",
    "df2['TYPE_VOIE'] =  df2['rue_init'].str.split(' ').str[0]\n",
    "df = pd.concat([df, df2], ignore_index=True)\n",
    "df['rue_init'] = df['rue_init'].astype(str)\n",
    "df['PROP_LEV'] = df['PROP_LEV'].astype(str)# Calculer des mesures de similarité\n",
    "df[\"damerau_levenshtein\"] = df.apply(lambda x: textdistance.damerau_levenshtein.normalized_similarity(x[\"rue_init\"], x[\"PROP_LEV\"]), axis=1)\n",
    "df[\"jaro_winkler\"] = df.apply(lambda x: textdistance.jaro_winkler(x[\"rue_init\"], x[\"PROP_LEV\"]), axis=1)\n",
    "df[\"jaro\"] = df.apply(lambda x: textdistance.jaro(x[\"rue_init\"], x[\"PROP_LEV\"]), axis=1)\n",
    "\n",
    "# Calcul de la mesure de Sørensen-Dice pour chaque paire d'adresses\n",
    "df['sorensen_dice'] = df.apply(lambda x: textdistance.sorensen_dice(x['rue_init'], x['PROP_LEV']), axis=1)\n",
    "\n",
    "# Calcul de la plus longue sous-séquence commune (LCS) pour chaque paire d'adresses\n",
    "df['lcs'] = df.apply(lambda x: textdistance.lcsstr.normalized_similarity(x['rue_init'], x['PROP_LEV']), axis=1)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Préparer les données pour l'entraînement\n",
    "X = df[[\"damerau_levenshtein\",  \"jaro_winkler\", \"jaro\",\"sorensen_dice\", \"lcs\"]]\n",
    "y = df[\"LABEL\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=35)\n",
    "\n",
    "\n",
    "# Commencer une expérience MLflow\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Paramètres expérimentaux\n",
    "    i = 4000\n",
    "    j = 1000\n",
    "    test_size = 0.1\n",
    "    random_state = 35\n",
    "    \n",
    "    # Log des paramètres\n",
    "    mlflow.log_param(\"i\", i)\n",
    "    mlflow.log_param(\"j\", j)\n",
    "    mlflow.log_param(\"test_size\", test_size)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "    \n",
    "    # Préparation et entraînement du modèle comme avant\n",
    "    # ...\n",
    "    \n",
    "    # Entraînement du modèle\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédictions et évaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Log des métriques\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    mlflow.log_metric(\"precision\", report['weighted avg']['precision'])\n",
    "    mlflow.log_metric(\"recall\", report['weighted avg']['recall'])\n",
    "    mlflow.log_metric(\"f1-score\", report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # Log du modèle\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
