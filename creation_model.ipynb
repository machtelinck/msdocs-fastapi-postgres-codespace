{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec /bin/python3 nécessitent le package ipykernel.\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\u001b[1;31mCommande : '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import textdistance\n",
    "\n",
    "# Configuration initiale de MLflow (facultatif)\n",
    "# mlflow.set_tracking_uri('votre_uri_de_suivi')\n",
    "\n",
    "# Lecture des données\n",
    "df = pd.read_excel(\"DONNEE_LABEL_FAUX_REGROUPER.xlsx\")\n",
    "df2 = pd.read_excel(\"DONNEE_LABEL_VRAI.xlsx\")\n",
    "# Votre prétraitement des données reste inchangé...\n",
    "i = 4000\n",
    "df = df.head(i)\n",
    "# i est la ou je me suis arreté\n",
    "# Renommer les colonnes par leur position\n",
    "df = df.rename(columns={df.columns[0]: 'rue_init', df.columns[1]: 'PROP_LEV',df.columns[2]: 'LABEL'})\n",
    "df = df.replace(np.nan, 0)\n",
    "df['TYPE_VOIE'] =  df['rue_init'].str.split(' ').str[0]\n",
    "df = df.replace(np.nan, 1)\n",
    "\n",
    "df2 = df2.replace(np.nan, 1)\n",
    "j = 1000\n",
    "# i est la ou je me suis arreté\n",
    "df2 = df2.head(j)\n",
    "df2 = df2.rename(columns={df2.columns[0]: 'rue_init', df2.columns[1]: 'PROP_LEV',df2.columns[2]: 'LABEL'})\n",
    "\n",
    "df2['TYPE_VOIE'] =  df2['rue_init'].str.split(' ').str[0]\n",
    "df = pd.concat([df, df2], ignore_index=True)\n",
    "df['rue_init'] = df['rue_init'].astype(str)\n",
    "df['PROP_LEV'] = df['PROP_LEV'].astype(str)# Calculer des mesures de similarité\n",
    "df[\"damerau_levenshtein\"] = df.apply(lambda x: textdistance.damerau_levenshtein.normalized_similarity(x[\"rue_init\"], x[\"PROP_LEV\"]), axis=1)\n",
    "df[\"jaro_winkler\"] = df.apply(lambda x: textdistance.jaro_winkler(x[\"rue_init\"], x[\"PROP_LEV\"]), axis=1)\n",
    "df[\"jaro\"] = df.apply(lambda x: textdistance.jaro(x[\"rue_init\"], x[\"PROP_LEV\"]), axis=1)\n",
    "\n",
    "# Calcul de la mesure de Sørensen-Dice pour chaque paire d'adresses\n",
    "df['sorensen_dice'] = df.apply(lambda x: textdistance.sorensen_dice(x['rue_init'], x['PROP_LEV']), axis=1)\n",
    "\n",
    "# Calcul de la plus longue sous-séquence commune (LCS) pour chaque paire d'adresses\n",
    "df['lcs'] = df.apply(lambda x: textdistance.lcsstr.normalized_similarity(x['rue_init'], x['PROP_LEV']), axis=1)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Préparer les données pour l'entraînement\n",
    "X = df[[\"damerau_levenshtein\",  \"jaro_winkler\", \"jaro\",\"sorensen_dice\", \"lcs\"]]\n",
    "y = df[\"LABEL\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=35)\n",
    "\n",
    "\n",
    "# Commencer une expérience MLflow\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Paramètres expérimentaux\n",
    "    i = 4000\n",
    "    j = 1000\n",
    "    test_size = 0.1\n",
    "    random_state = 35\n",
    "    \n",
    "    # Log des paramètres\n",
    "    mlflow.log_param(\"i\", i)\n",
    "    mlflow.log_param(\"j\", j)\n",
    "    mlflow.log_param(\"test_size\", test_size)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "    \n",
    "    # Préparation et entraînement du modèle comme avant\n",
    "    # ...\n",
    "    \n",
    "    # Entraînement du modèle\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédictions et évaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Log des métriques\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    mlflow.log_metric(\"precision\", report['weighted avg']['precision'])\n",
    "    mlflow.log_metric(\"recall\", report['weighted avg']['recall'])\n",
    "    mlflow.log_metric(\"f1-score\", report['weighted avg']['f1-score'])\n",
    "    \n",
    "    # Log du modèle\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLes cellules en cours d’exécution avec /bin/python3 nécessitent le package ipykernel.\n",
      "\u001b[1;31mExécutez la commande suivante pour installer 'ipykernel' dans l’environnement Python. \n",
      "\u001b[1;31mCommande : '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
