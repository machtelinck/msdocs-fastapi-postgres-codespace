{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier \n",
    "import textdistance\n",
    "\n",
    "# Configuration initiale de MLflow (facultatif)\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"workspace/ml_runs/\")\n",
    "experiment_name = \"spacy_test\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Configurer MLflow pour utiliser un dossier local pour le stockage\n",
    "\n",
    "\n",
    "# Assurez-vous de créer le dossier s'il n'existe pas déjà\n",
    "\n",
    "\n",
    "\n",
    "# Lecture des données\n",
    "df = pd.read_excel(\"/workspace/DONNEE_LABEL_FAUX_REGROUPER.xlsx\")\n",
    "df2 = pd.read_excel(\"/workspace/DONNEE_LABEL_VRAI.xlsx\")\n",
    "# Votre prétraitement des données reste inchangé...\n",
    "i = 4000\n",
    "df = df.head(i)\n",
    "# i est la ou je me suis arreté\n",
    "# Renommer les colonnes par leur position\n",
    "df = df.rename(columns={df.columns[0]: 'rue_init', df.columns[1]: 'PROP_LEV',df.columns[2]: 'LABEL'})\n",
    "df = df.replace(np.nan, 0)\n",
    "df['TYPE_VOIE'] =  df['rue_init'].str.split(' ').str[0]\n",
    "df = df.replace(np.nan, 1)\n",
    "\n",
    "df2 = df2.replace(np.nan, 1)\n",
    "j = 1000\n",
    "# i est la ou je me suis arreté\n",
    "df2 = df2.head(j)\n",
    "df2 = df2.rename(columns={df2.columns[0]: 'rue_init', df2.columns[1]: 'PROP_LEV',df2.columns[2]: 'LABEL'})\n",
    "\n",
    "df2['TYPE_VOIE'] =  df2['rue_init'].str.split(' ').str[0]\n",
    "df = pd.concat([df, df2], ignore_index=True)\n",
    "df['rue_init'] = df['rue_init'].astype(str)\n",
    "df['PROP_LEV'] = df['PROP_LEV'].astype(str)# Calculer des mesures de similarité\n",
    "df[\"damerau_levenshtein\"] = df.apply(lambda x: textdistance.damerau_levenshtein.normalized_similarity(x[\"rue_init\"], x[\"PROP_LEV\"]), axis=1)\n",
    "df[\"jaro_winkler\"] = df.apply(lambda x: textdistance.jaro_winkler(x[\"rue_init\"], x[\"PROP_LEV\"]), axis=1)\n",
    "df[\"jaro\"] = df.apply(lambda x: textdistance.jaro(x[\"rue_init\"], x[\"PROP_LEV\"]), axis=1)\n",
    "\n",
    "# Calcul de la mesure de Sørensen-Dice pour chaque paire d'adresses\n",
    "df['sorensen_dice'] = df.apply(lambda x: textdistance.sorensen_dice(x['rue_init'], x['PROP_LEV']), axis=1)\n",
    "\n",
    "# Calcul de la plus longue sous-séquence commune (LCS) pour chaque paire d'adresses\n",
    "df['lcs'] = df.apply(lambda x: textdistance.lcsstr.normalized_similarity(x['rue_init'], x['PROP_LEV']), axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textdistance\n",
    "\n",
    "# Charger le modèle linguistique français\n",
    "# Charger le modèle linguistique français medium\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "\n",
    "\n",
    "# Fonction pour extraire le premier nom propre d'une chaîne de caractères\n",
    "def extract_first_proper_noun(text):\n",
    "    doc = nlp(text)\n",
    "    proper_nouns = [token.text for token in doc if token.pos_ == \"PROPN\"]\n",
    "    return \" \".join(proper_nouns)\n",
    "\n",
    "\n",
    "# Appliquer la fonction d'extraction sur 'rue_init' et 'PROP_LEV'\n",
    "df['rue_init_name'] = df['rue_init'].apply(extract_first_proper_noun)\n",
    "df['PROP_LEV_name'] = df['PROP_LEV'].apply(extract_first_proper_noun)\n",
    "\n",
    "# Calculer la distance de Levenshtein et le score LCS sur les noms extraits\n",
    "df[\"levenshtein_name_distance\"] = df.apply(lambda x: textdistance.damerau_levenshtein.normalized_similarity(x[\"rue_init_name\"], x[\"PROP_LEV_name\"]), axis=1)\n",
    "df[\"lcs_name_score\"] = df.apply(lambda x: textdistance.lcsstr.normalized_similarity(x[\"rue_init_name\"], x[\"PROP_LEV_name\"]), axis=1)\n",
    "\n",
    "# Mise à jour de l'ensemble des features pour inclure les nouvelles colonnes calculées\n",
    "X = df[[\"damerau_levenshtein\", \"jaro_winkler\", \"jaro\", \"sorensen_dice\", \"lcs\", \"levenshtein_name_distance\", \"lcs_name_score\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rue_init</th>\n",
       "      <th>PROP_LEV</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>TYPE_VOIE</th>\n",
       "      <th>damerau_levenshtein</th>\n",
       "      <th>jaro_winkler</th>\n",
       "      <th>jaro</th>\n",
       "      <th>sorensen_dice</th>\n",
       "      <th>lcs</th>\n",
       "      <th>rue_init_name</th>\n",
       "      <th>PROP_LEV_name</th>\n",
       "      <th>levenshtein_name_distance</th>\n",
       "      <th>lcs_name_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A RUE DE L ORMETEAU</td>\n",
       "      <td>AVENUE DE L EUROPE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.790100</td>\n",
       "      <td>0.766778</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>ORMETEAU</td>\n",
       "      <td>AVENUE EUROPE</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A RUE DU CHEMIN DE FER</td>\n",
       "      <td>RUE LHOMOND</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>FER</td>\n",
       "      <td>LHOMOND</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A RUE DU DOCTEUR ROUX</td>\n",
       "      <td>BD DU COMTE DE MONTALEMBERT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.585538</td>\n",
       "      <td>0.585538</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.148148</td>\n",
       "      <td></td>\n",
       "      <td>BD COMTE</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A/43 RUE JEAN BAPTISTE NOTTE</td>\n",
       "      <td>AVENUE JEAN BAPTISTE LEBAS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A/43</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.677839</td>\n",
       "      <td>0.677839</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>A/43 JEAN BAPTISTE NOTTE</td>\n",
       "      <td>AVENUE JEAN BAPTISTE LEBAS</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A1 ROUTE NATIONALE</td>\n",
       "      <td>RUE DU HAUIT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A1</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>NATIONALE</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>IMPASSE ARTHUR LEDENT</td>\n",
       "      <td>IMPASSE LEDENT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMPASSE</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td></td>\n",
       "      <td>LEDENT</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>RUE D ORESMIEUX</td>\n",
       "      <td>ALLEE DES CERISIERS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>RUE</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.543080</td>\n",
       "      <td>0.543080</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>ORESMIEUX</td>\n",
       "      <td>ALLEE</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>AVENUE PIERRE MENDES FRANCE</td>\n",
       "      <td>RUE ADRIEN DANVERS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.681327</td>\n",
       "      <td>0.681327</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>AVENUE FRANCE</td>\n",
       "      <td>ADRIEN</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>AVENUE DU MARCHAL FOCH</td>\n",
       "      <td>AVENUE DU MARECHAL FOCH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AVENUE</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.991304</td>\n",
       "      <td>0.985507</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>FOCH</td>\n",
       "      <td>FOCH</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>PORT D'AMONT</td>\n",
       "      <td>PORT D AMONT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PORT</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>AMONT</td>\n",
       "      <td>AMONT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          rue_init                     PROP_LEV  LABEL  \\\n",
       "0              A RUE DE L ORMETEAU           AVENUE DE L EUROPE    0.0   \n",
       "1           A RUE DU CHEMIN DE FER                  RUE LHOMOND    0.0   \n",
       "2            A RUE DU DOCTEUR ROUX  BD DU COMTE DE MONTALEMBERT    0.0   \n",
       "3     A/43 RUE JEAN BAPTISTE NOTTE   AVENUE JEAN BAPTISTE LEBAS    0.0   \n",
       "4               A1 ROUTE NATIONALE                 RUE DU HAUIT    0.0   \n",
       "...                            ...                          ...    ...   \n",
       "4995         IMPASSE ARTHUR LEDENT               IMPASSE LEDENT    1.0   \n",
       "4996               RUE D ORESMIEUX          ALLEE DES CERISIERS    0.0   \n",
       "4997   AVENUE PIERRE MENDES FRANCE           RUE ADRIEN DANVERS    0.0   \n",
       "4998        AVENUE DU MARCHAL FOCH      AVENUE DU MARECHAL FOCH    1.0   \n",
       "4999                  PORT D'AMONT                 PORT D AMONT    1.0   \n",
       "\n",
       "     TYPE_VOIE  damerau_levenshtein  jaro_winkler      jaro  sorensen_dice  \\\n",
       "0            A             0.473684      0.790100  0.766778       0.756757   \n",
       "1            A             0.363636      0.530303  0.530303       0.484848   \n",
       "2            A             0.296296      0.585538  0.585538       0.625000   \n",
       "3         A/43             0.642857      0.677839  0.677839       0.740741   \n",
       "4           A1             0.222222      0.537037  0.537037       0.533333   \n",
       "...        ...                  ...           ...       ...            ...   \n",
       "4995   IMPASSE             0.666667      0.890476  0.817460       0.800000   \n",
       "4996       RUE             0.368421      0.543080  0.543080       0.588235   \n",
       "4997    AVENUE             0.296296      0.681327  0.681327       0.755556   \n",
       "4998    AVENUE             0.956522      0.991304  0.985507       0.977778   \n",
       "4999      PORT             0.916667      0.966667  0.944444       0.916667   \n",
       "\n",
       "           lcs             rue_init_name               PROP_LEV_name  \\\n",
       "0     0.421053                  ORMETEAU               AVENUE EUROPE   \n",
       "1     0.181818                       FER                     LHOMOND   \n",
       "2     0.148148                                              BD COMTE   \n",
       "3     0.607143  A/43 JEAN BAPTISTE NOTTE  AVENUE JEAN BAPTISTE LEBAS   \n",
       "4     0.111111                 NATIONALE                               \n",
       "...        ...                       ...                         ...   \n",
       "4995  0.380952                                                LEDENT   \n",
       "4996  0.157895                 ORESMIEUX                       ALLEE   \n",
       "4997  0.111111             AVENUE FRANCE                      ADRIEN   \n",
       "4998  0.565217                      FOCH                        FOCH   \n",
       "4999  0.500000                     AMONT                       AMONT   \n",
       "\n",
       "      levenshtein_name_distance  lcs_name_score  \n",
       "0                      0.153846        0.076923  \n",
       "1                      0.000000        0.000000  \n",
       "2                      0.000000        0.000000  \n",
       "3                      0.615385        0.576923  \n",
       "4                      0.000000        0.000000  \n",
       "...                         ...             ...  \n",
       "4995                   0.000000        0.000000  \n",
       "4996                   0.111111        0.111111  \n",
       "4997                   0.230769        0.153846  \n",
       "4998                   1.000000        1.000000  \n",
       "4999                   1.000000        1.000000  \n",
       "\n",
       "[5000 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.95      0.94       365\n",
      "         1.0       0.86      0.79      0.83       135\n",
      "\n",
      "    accuracy                           0.91       500\n",
      "   macro avg       0.89      0.87      0.88       500\n",
      "weighted avg       0.91      0.91      0.91       500\n",
      "\n",
      "Matrice de confusion :\n",
      "[[348  17]\n",
      " [ 28 107]]\n"
     ]
    }
   ],
   "source": [
    "# Continuation du code précédent...\n",
    "\n",
    "# Mise à jour de l'ensemble des features pour inclure les nouvelles colonnes calculées\n",
    "# Assurez-vous que cette liste inclut toutes les features que vous souhaitez utiliser pour l'entraînement\n",
    "features = [\"damerau_levenshtein\", \"jaro_winkler\", \"sorensen_dice\", \"lcs\", \n",
    "            \"levenshtein_name_distance\", \"lcs_name_score\"]\n",
    "X = df[features]\n",
    "y = df[\"LABEL\"]\n",
    "\n",
    "# Séparation des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=35)\n",
    "\n",
    "# Entraînement du modèle XGBClassifier\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='error')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluation du modèle\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Logging des métriques avec MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params({\n",
    "        \"i\": len(df),\n",
    "        \"test_size\": 0.1,\n",
    "        \"random_state\": 35,\n",
    "        # Ajoutez d'autres paramètres expérimentaux ici si nécessaire\n",
    "    })\n",
    "    \n",
    "    # Log des métriques de performance\n",
    "    mlflow.log_metric(\"precision\", report['weighted avg']['precision'])\n",
    "    mlflow.log_metric(\"recall\", report['weighted avg']['recall'])\n",
    "    mlflow.log_metric(\"f1-score\", report['weighted avg']['f1-score'])\n",
    "\n",
    "    # Log du modèle\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "# Affichage du rapport de classification et de la matrice de confusion\n",
    "print(\"Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Matrice de confusion :\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-logloss:0.42847\ttest-f1:-0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttest-logloss:0.36198\ttest-f1:-0.59512\n",
      "[2]\ttest-logloss:0.32114\ttest-f1:-0.71366\n",
      "[3]\ttest-logloss:0.29361\ttest-f1:-0.74894\n",
      "[4]\ttest-logloss:0.27612\ttest-f1:-0.76471\n",
      "[5]\ttest-logloss:0.26790\ttest-f1:-0.76987\n",
      "[6]\ttest-logloss:0.26154\ttest-f1:-0.77686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [10:27:24] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\ttest-logloss:0.25716\ttest-f1:-0.78688\n",
      "[8]\ttest-logloss:0.25401\ttest-f1:-0.79184\n",
      "[9]\ttest-logloss:0.25068\ttest-f1:-0.79675\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "\n",
    "def f1_eval(y_pred, dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    # Transformer les probabilités de prédiction en classe binaire (0 ou 1) basées sur un seuil (par exemple, 0.5)\n",
    "    y_pred_binary = [int(value > 0.5) for value in y_pred]\n",
    "    return 'f1', -f1_score(y_true, y_pred_binary)\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "# Transformer les ensembles de données en DMatrix, format requis par XGBoost pour l'utilisation des callbacks personnalisés\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Paramètres pour XGBoost\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'use_label_encoder': False\n",
    "}\n",
    "\n",
    "# Entraînement du modèle avec le callback personnalisé pour F1\n",
    "model = xgb.train(params, dtrain, evals=[(dtest, \"test\")], feval=f1_eval, maximize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Définition de l'espace d'hyperparamètres à explorer\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Initialisation du classificateur XGBoost\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Définition du scorer F1 pour GridSearchCV\n",
    "f1_scorer = make_scorer(f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.3s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.01, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=6, n_estimators=150; total time=   0.2s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.1, max_depth=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END ....learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=5, n_estimators=150; total time=   0.2s\n",
      "[CV] END ....learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END ....learning_rate=0.2, max_depth=6, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=100; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.2s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END ...learning_rate=0.2, max_depth=6, n_estimators=150; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5, 6],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
       "             scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;),\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric=&#x27;logloss&#x27;, feature_types=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
       "                         &#x27;max_depth&#x27;: [3, 4, 5, 6],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 150]},\n",
       "             scoring=make_scorer(f1_score, response_method=&#x27;predict&#x27;),\n",
       "             verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='logloss', feature_types=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=...\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 4, 5, 6],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             scoring=make_scorer(f1_score, response_method='predict'),\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration de GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid, scoring=f1_scorer, cv=5, verbose=2)\n",
    "\n",
    "# Entraînement\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres :  {'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 150}\n",
      "Meilleur score F1 :  0.854070265728825\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs hyperparamètres : \", grid_search.best_params_)\n",
    "print(\"Meilleur score F1 : \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supposons que X_train, X_test, y_train, y_test sont déjà définis\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "n_estimators_values = [30,35,40,45,50]\n",
    "f1_scores = []\n",
    "\n",
    "for n_estimators in n_estimators_values:\n",
    "    model = XGBClassifier(n_estimators=n_estimators, use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    f1_scores.append(score)\n",
    "\n",
    "# Tracer le graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_estimators_values, f1_scores, marker='o', linestyle='-')\n",
    "plt.title('F1 Score en fonction du nombre d\\'estimators')\n",
    "plt.xlabel('Nombre d\\'estimators')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-03-21 10:32:46,238] A new study created in memory with name: no-name-27ec20dc-9429-4dd3-ac52-d3b85583e8ef\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:46,299] Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 35, 'max_depth': 6, 'learning_rate': 0.0030175685238745314}. Best is trial 0 with value: 0.0.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:46,423] Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 40, 'max_depth': 23, 'learning_rate': 2.5880449085394574e-06}. Best is trial 0 with value: 0.0.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:46,524] Trial 2 finished with value: 0.0 and parameters: {'n_estimators': 40, 'max_depth': 22, 'learning_rate': 6.447885129513148e-08}. Best is trial 0 with value: 0.0.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:46,630] Trial 3 finished with value: 0.0 and parameters: {'n_estimators': 40, 'max_depth': 16, 'learning_rate': 6.328850117205425e-07}. Best is trial 0 with value: 0.0.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:46,671] Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 38, 'max_depth': 5, 'learning_rate': 0.007386254374013816}. Best is trial 0 with value: 0.0.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:46,783] Trial 5 finished with value: 0.0 and parameters: {'n_estimators': 38, 'max_depth': 10, 'learning_rate': 5.4019045651116715e-08}. Best is trial 0 with value: 0.0.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:46,880] Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 38, 'max_depth': 25, 'learning_rate': 0.00028059105188135567}. Best is trial 0 with value: 0.0.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:46,915] Trial 7 finished with value: 0.7936507936507936 and parameters: {'n_estimators': 37, 'max_depth': 4, 'learning_rate': 0.07221824839043615}. Best is trial 7 with value: 0.7936507936507936.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,013] Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 39, 'max_depth': 13, 'learning_rate': 3.959576192207119e-05}. Best is trial 7 with value: 0.7936507936507936.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,112] Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 39, 'max_depth': 24, 'learning_rate': 1.709588304692771e-06}. Best is trial 7 with value: 0.7936507936507936.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,147] Trial 10 finished with value: 0.8 and parameters: {'n_estimators': 36, 'max_depth': 2, 'learning_rate': 0.6748912707162873}. Best is trial 10 with value: 0.8.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,195] Trial 11 finished with value: 0.8060836501901141 and parameters: {'n_estimators': 36, 'max_depth': 2, 'learning_rate': 0.6745191321709685}. Best is trial 11 with value: 0.8060836501901141.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,234] Trial 12 finished with value: 0.7923076923076923 and parameters: {'n_estimators': 36, 'max_depth': 3, 'learning_rate': 0.7340861796609339}. Best is trial 11 with value: 0.8060836501901141.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,274] Trial 13 finished with value: 0.8 and parameters: {'n_estimators': 35, 'max_depth': 2, 'learning_rate': 0.6979445817547753}. Best is trial 11 with value: 0.8060836501901141.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,358] Trial 14 finished with value: 0.7666666666666667 and parameters: {'n_estimators': 36, 'max_depth': 8, 'learning_rate': 0.022622219452778296}. Best is trial 11 with value: 0.8060836501901141.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,561] Trial 15 finished with value: 0.803088803088803 and parameters: {'n_estimators': 36, 'max_depth': 11, 'learning_rate': 0.15448305833797585}. Best is trial 11 with value: 0.8060836501901141.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,689] Trial 16 finished with value: 0.0 and parameters: {'n_estimators': 37, 'max_depth': 17, 'learning_rate': 0.0006809874458179374}. Best is trial 11 with value: 0.8060836501901141.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,809] Trial 17 finished with value: 0.7969348659003831 and parameters: {'n_estimators': 35, 'max_depth': 12, 'learning_rate': 0.07412954224742954}. Best is trial 11 with value: 0.8060836501901141.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,908] Trial 18 finished with value: 0.0 and parameters: {'n_estimators': 36, 'max_depth': 19, 'learning_rate': 3.7978159299456934e-05}. Best is trial 11 with value: 0.8060836501901141.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:47,979] Trial 19 finished with value: 0.816793893129771 and parameters: {'n_estimators': 37, 'max_depth': 8, 'learning_rate': 0.161546867006483}. Best is trial 19 with value: 0.816793893129771.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:48,063] Trial 20 finished with value: 0.0 and parameters: {'n_estimators': 37, 'max_depth': 8, 'learning_rate': 0.002403081460580883}. Best is trial 19 with value: 0.816793893129771.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:48,212] Trial 21 finished with value: 0.8217054263565892 and parameters: {'n_estimators': 36, 'max_depth': 10, 'learning_rate': 0.09740464504975754}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:48,319] Trial 22 finished with value: 0.8122605363984674 and parameters: {'n_estimators': 37, 'max_depth': 8, 'learning_rate': 0.10168493063403473}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:48,442] Trial 23 finished with value: 0.7467811158798283 and parameters: {'n_estimators': 37, 'max_depth': 9, 'learning_rate': 0.01911554432926606}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:48,520] Trial 24 finished with value: 0.803030303030303 and parameters: {'n_estimators': 37, 'max_depth': 7, 'learning_rate': 0.10861227202582335}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:48,639] Trial 25 finished with value: 0.7467811158798283 and parameters: {'n_estimators': 38, 'max_depth': 15, 'learning_rate': 0.019004567011443804}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:48,751] Trial 26 finished with value: 0.0 and parameters: {'n_estimators': 37, 'max_depth': 10, 'learning_rate': 0.0010034219936885338}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:48,810] Trial 27 finished with value: 0.803030303030303 and parameters: {'n_estimators': 39, 'max_depth': 6, 'learning_rate': 0.1809855584289535}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:48,915] Trial 28 finished with value: 0.0 and parameters: {'n_estimators': 35, 'max_depth': 14, 'learning_rate': 0.007638782267647202}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:48,980] Trial 29 finished with value: 0.0 and parameters: {'n_estimators': 35, 'max_depth': 6, 'learning_rate': 0.004702700043735226}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:49,079] Trial 30 finished with value: 0.0 and parameters: {'n_estimators': 36, 'max_depth': 12, 'learning_rate': 1.045399488470732e-08}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:49,135] Trial 31 finished with value: 0.8 and parameters: {'n_estimators': 36, 'max_depth': 4, 'learning_rate': 0.2702326167219854}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:49,242] Trial 32 finished with value: 0.8 and parameters: {'n_estimators': 37, 'max_depth': 8, 'learning_rate': 0.038462021762217025}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:49,404] Trial 33 finished with value: 0.8093385214007782 and parameters: {'n_estimators': 36, 'max_depth': 10, 'learning_rate': 0.2686752963429651}. Best is trial 21 with value: 0.8217054263565892.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:49,489] Trial 34 finished with value: 0.8275862068965517 and parameters: {'n_estimators': 37, 'max_depth': 11, 'learning_rate': 0.27541339026204936}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:49,612] Trial 35 finished with value: 0.7871485943775101 and parameters: {'n_estimators': 38, 'max_depth': 12, 'learning_rate': 0.04010287143149786}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:49,689] Trial 36 finished with value: 0.0 and parameters: {'n_estimators': 37, 'max_depth': 7, 'learning_rate': 0.010031064483556253}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:49,795] Trial 37 finished with value: 0.0 and parameters: {'n_estimators': 38, 'max_depth': 9, 'learning_rate': 0.002756079963787615}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:49,897] Trial 38 finished with value: 0.8257575757575758 and parameters: {'n_estimators': 37, 'max_depth': 18, 'learning_rate': 0.27230473528215277}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:50,011] Trial 39 finished with value: 0.0 and parameters: {'n_estimators': 38, 'max_depth': 19, 'learning_rate': 0.0001437000734345168}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:50,214] Trial 40 finished with value: 0.8199233716475096 and parameters: {'n_estimators': 37, 'max_depth': 21, 'learning_rate': 0.35064124792031964}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:50,335] Trial 41 finished with value: 0.8122605363984674 and parameters: {'n_estimators': 37, 'max_depth': 21, 'learning_rate': 0.2685522705306816}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:50,416] Trial 42 finished with value: 0.7906976744186046 and parameters: {'n_estimators': 37, 'max_depth': 21, 'learning_rate': 0.9167329327899599}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:50,603] Trial 43 finished with value: 0.8015873015873016 and parameters: {'n_estimators': 38, 'max_depth': 17, 'learning_rate': 0.04240759509221826}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:50,730] Trial 44 finished with value: 0.8122605363984674 and parameters: {'n_estimators': 37, 'max_depth': 22, 'learning_rate': 0.24840885505785437}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:50,833] Trial 45 finished with value: 0.8226415094339623 and parameters: {'n_estimators': 36, 'max_depth': 14, 'learning_rate': 0.3105455204605614}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:50,981] Trial 46 finished with value: 0.0 and parameters: {'n_estimators': 36, 'max_depth': 19, 'learning_rate': 1.2475603606431571e-05}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:51,081] Trial 47 finished with value: 0.8108108108108109 and parameters: {'n_estimators': 36, 'max_depth': 14, 'learning_rate': 0.5183103057723126}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:51,170] Trial 48 finished with value: 0.8244274809160306 and parameters: {'n_estimators': 35, 'max_depth': 16, 'learning_rate': 0.46399347495746573}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:51,308] Trial 49 finished with value: 0.8076923076923077 and parameters: {'n_estimators': 35, 'max_depth': 16, 'learning_rate': 0.06441992899147174}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:51,414] Trial 50 finished with value: 0.6728971962616822 and parameters: {'n_estimators': 35, 'max_depth': 17, 'learning_rate': 0.01455063759476172}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:51,501] Trial 51 finished with value: 0.8212927756653993 and parameters: {'n_estimators': 35, 'max_depth': 15, 'learning_rate': 0.4713129070153929}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:51,590] Trial 52 finished with value: 0.8122605363984674 and parameters: {'n_estimators': 35, 'max_depth': 15, 'learning_rate': 0.4780499069791026}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:51,670] Trial 53 finished with value: 0.8075471698113208 and parameters: {'n_estimators': 35, 'max_depth': 18, 'learning_rate': 0.9222185441151964}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:51,775] Trial 54 finished with value: 0.0 and parameters: {'n_estimators': 35, 'max_depth': 13, 'learning_rate': 3.605206822481378e-07}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:51,895] Trial 55 finished with value: 0.8153846153846154 and parameters: {'n_estimators': 36, 'max_depth': 15, 'learning_rate': 0.10031797678580057}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:52,011] Trial 56 finished with value: 0.803088803088803 and parameters: {'n_estimators': 35, 'max_depth': 11, 'learning_rate': 0.06007823163701335}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:52,095] Trial 57 finished with value: 0.8153846153846154 and parameters: {'n_estimators': 36, 'max_depth': 13, 'learning_rate': 0.43923788923524515}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:52,202] Trial 58 finished with value: 0.8185328185328186 and parameters: {'n_estimators': 36, 'max_depth': 16, 'learning_rate': 0.14772737966924962}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:52,338] Trial 59 finished with value: 0.7804878048780488 and parameters: {'n_estimators': 35, 'max_depth': 14, 'learning_rate': 0.0327193889215419}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:52,445] Trial 60 finished with value: 0.8153846153846154 and parameters: {'n_estimators': 35, 'max_depth': 16, 'learning_rate': 0.13940403992082537}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:52,553] Trial 61 finished with value: 0.8153846153846154 and parameters: {'n_estimators': 37, 'max_depth': 20, 'learning_rate': 0.38431190517683017}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:52,677] Trial 62 finished with value: 0.7906976744186046 and parameters: {'n_estimators': 36, 'max_depth': 24, 'learning_rate': 0.8946649387544874}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:52,872] Trial 63 finished with value: 0.8212927756653993 and parameters: {'n_estimators': 37, 'max_depth': 18, 'learning_rate': 0.37629363750293116}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:52,999] Trial 64 finished with value: 0.8217054263565892 and parameters: {'n_estimators': 40, 'max_depth': 18, 'learning_rate': 0.07954472991335267}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:53,115] Trial 65 finished with value: 0.8093385214007782 and parameters: {'n_estimators': 40, 'max_depth': 11, 'learning_rate': 0.0784808324352051}. Best is trial 34 with value: 0.8275862068965517.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:53,231] Trial 66 finished with value: 0.8307692307692308 and parameters: {'n_estimators': 40, 'max_depth': 18, 'learning_rate': 0.1873965703882353}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:53,366] Trial 67 finished with value: 0.0 and parameters: {'n_estimators': 40, 'max_depth': 18, 'learning_rate': 0.001351855434894802}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:53,494] Trial 68 finished with value: 0.7755102040816326 and parameters: {'n_estimators': 40, 'max_depth': 17, 'learning_rate': 0.027491647638063912}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:53,609] Trial 69 finished with value: 0.6411483253588517 and parameters: {'n_estimators': 39, 'max_depth': 20, 'learning_rate': 0.012172615486337973}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:53,718] Trial 70 finished with value: 0.0 and parameters: {'n_estimators': 40, 'max_depth': 10, 'learning_rate': 0.0051496037522932026}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:53,847] Trial 71 finished with value: 0.816793893129771 and parameters: {'n_estimators': 40, 'max_depth': 15, 'learning_rate': 0.1755222935553607}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:53,961] Trial 72 finished with value: 0.8288973384030418 and parameters: {'n_estimators': 39, 'max_depth': 16, 'learning_rate': 0.1936372600765964}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:54,095] Trial 73 finished with value: 0.8122605363984674 and parameters: {'n_estimators': 39, 'max_depth': 16, 'learning_rate': 0.19962863319273447}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:54,220] Trial 74 finished with value: 0.8125 and parameters: {'n_estimators': 39, 'max_depth': 19, 'learning_rate': 0.0604351036401148}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:54,360] Trial 75 finished with value: 0.8076923076923077 and parameters: {'n_estimators': 40, 'max_depth': 13, 'learning_rate': 0.10012635143913183}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:54,571] Trial 76 finished with value: 0.7717842323651453 and parameters: {'n_estimators': 39, 'max_depth': 17, 'learning_rate': 0.022583903522863758}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:54,676] Trial 77 finished with value: 0.0 and parameters: {'n_estimators': 39, 'max_depth': 12, 'learning_rate': 0.0004331014327746939}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:54,782] Trial 78 finished with value: 0.8093385214007782 and parameters: {'n_estimators': 40, 'max_depth': 14, 'learning_rate': 0.23600871251868033}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:54,872] Trial 79 finished with value: 0.803088803088803 and parameters: {'n_estimators': 38, 'max_depth': 18, 'learning_rate': 0.5935932478245094}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:54,964] Trial 80 finished with value: 0.816793893129771 and parameters: {'n_estimators': 40, 'max_depth': 9, 'learning_rate': 0.119876086613867}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:55,054] Trial 81 finished with value: 0.8045977011494253 and parameters: {'n_estimators': 36, 'max_depth': 16, 'learning_rate': 0.5953533615881792}. Best is trial 66 with value: 0.8307692307692308.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:55,156] Trial 82 finished with value: 0.833976833976834 and parameters: {'n_estimators': 40, 'max_depth': 15, 'learning_rate': 0.32609828922050993}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:55,293] Trial 83 finished with value: 0.8031496062992126 and parameters: {'n_estimators': 40, 'max_depth': 17, 'learning_rate': 0.04798327003632484}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:55,509] Trial 84 finished with value: 0.8153846153846154 and parameters: {'n_estimators': 40, 'max_depth': 20, 'learning_rate': 0.30558353774539126}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:55,631] Trial 85 finished with value: 0.8199233716475096 and parameters: {'n_estimators': 40, 'max_depth': 18, 'learning_rate': 0.18964177572031143}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:55,758] Trial 86 finished with value: 0.8185328185328186 and parameters: {'n_estimators': 39, 'max_depth': 14, 'learning_rate': 0.08181822578608865}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:55,861] Trial 87 finished with value: 0.8153846153846154 and parameters: {'n_estimators': 38, 'max_depth': 12, 'learning_rate': 0.13576374136702746}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:56,090] Trial 88 finished with value: 0.7937743190661478 and parameters: {'n_estimators': 40, 'max_depth': 15, 'learning_rate': 0.9774323575519469}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:56,325] Trial 89 finished with value: 0.0 and parameters: {'n_estimators': 39, 'max_depth': 19, 'learning_rate': 6.9948155966877626e-06}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:56,458] Trial 90 finished with value: 0.8333333333333334 and parameters: {'n_estimators': 37, 'max_depth': 13, 'learning_rate': 0.2993803754253684}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:56,546] Trial 91 finished with value: 0.7984189723320159 and parameters: {'n_estimators': 37, 'max_depth': 11, 'learning_rate': 0.2886825009316863}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:56,701] Trial 92 finished with value: 0.7938931297709924 and parameters: {'n_estimators': 37, 'max_depth': 13, 'learning_rate': 0.6049981570279841}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:56,826] Trial 93 finished with value: 0.816793893129771 and parameters: {'n_estimators': 37, 'max_depth': 16, 'learning_rate': 0.20258649252650693}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:56,942] Trial 94 finished with value: 0.8015873015873016 and parameters: {'n_estimators': 37, 'max_depth': 11, 'learning_rate': 0.048553902640112806}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:57,042] Trial 95 finished with value: 0.8320610687022901 and parameters: {'n_estimators': 36, 'max_depth': 17, 'learning_rate': 0.33122098972684394}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:57,134] Trial 96 finished with value: 0.8185328185328186 and parameters: {'n_estimators': 36, 'max_depth': 15, 'learning_rate': 0.362985206666738}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:57,227] Trial 97 finished with value: 0.8326848249027238 and parameters: {'n_estimators': 36, 'max_depth': 17, 'learning_rate': 0.6537569062054828}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:57,321] Trial 98 finished with value: 0.8015564202334631 and parameters: {'n_estimators': 36, 'max_depth': 14, 'learning_rate': 0.672773479319542}. Best is trial 82 with value: 0.833976833976834.\n",
      "/tmp/ipykernel_2842/1520897030.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
      "[I 2024-03-21 10:32:57,436] Trial 99 finished with value: 0.8060836501901141 and parameters: {'n_estimators': 36, 'max_depth': 17, 'learning_rate': 0.44513138858206336}. Best is trial 82 with value: 0.833976833976834.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de trials terminés:  100\n",
      "Meilleur trial:\n",
      " Valeur:  0.833976833976834\n",
      " Hyperparamètres: \n",
      "    n_estimators: 40\n",
      "    max_depth: 15\n",
      "    learning_rate: 0.32609828922050993\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Supposons que X et y soient vos features et target\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggestion d'hyperparamètres\n",
    "    n_estimators = trial.suggest_int('n_estimators', 35, 40)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 25)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-8, 1.0)\n",
    "    \n",
    "    # Création et entraînement du modèle\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        learning_rate=learning_rate,\n",
    "        use_label_encoder=False, \n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcul du F1 score\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100) # Vous pouvez ajuster n_trials selon vos besoins\n",
    "\n",
    "print(\"Nombre de trials terminés: \", len(study.trials))\n",
    "print(\"Meilleur trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\" Valeur: \", trial.value)\n",
    "print(\" Hyperparamètres: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "# Remplacez X et y par vos données\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    classifier_name = trial.suggest_categorical('classifier', ['RandomForest', 'SVM', 'XGBoost'])\n",
    "    \n",
    "    if classifier_name == 'RandomForest':\n",
    "        rf_n_estimators = trial.suggest_int('rf_n_estimators', 10, 100)\n",
    "        model = RandomForestClassifier(n_estimators=rf_n_estimators)\n",
    "        \n",
    "    elif classifier_name == 'SVM':\n",
    "        svm_c = trial.suggest_float('svm_c', 1e-10, 1e10, log=True)\n",
    "        model = SVC(C=svm_c, gamma='auto')\n",
    "        \n",
    "    else: # XGBoost\n",
    "        xgb_n_estimators = trial.suggest_int('xgb_n_estimators', 35, 40)\n",
    "        xgb_max_depth = trial.suggest_int('xgb_max_depth', 2, 25)\n",
    "        xgb_learning_rate = trial.suggest_loguniform('xgb_learning_rate', 1e-8, 1.0)\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=xgb_n_estimators,\n",
    "            max_depth=xgb_max_depth,\n",
    "            learning_rate=xgb_learning_rate,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'study = optuna.create_study(direction=\\'maximize\\')\\nstudy.optimize(objective, n_trials=50)\\n\\nprint(\"Nombre de trials terminés: \", len(study.trials))\\nprint(\"Meilleur trial:\")\\ntrial = study.best_trial\\n\\nprint(\" Valeur: \", trial.value)\\nprint(\" Hyperparamètres: \")\\nfor key, value in trial.params.items():\\n    print(f\"    {key}: {value}\")'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Nombre de trials terminés: \", len(study.trials))\n",
    "print(\"Meilleur trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\" Valeur: \", trial.value)\n",
    "print(\" Hyperparamètres: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
